---
title: 'AI世界大入门'
authors: [zqqqj]
tags: [RL]
date: 2025-10-27
---

## introduction

这篇文章旨在理解一大堆杂七杂八的，狗屁倒灶的，ai 方向的专用名词，例 AI，NLP，CV，深度学习，强化学习等等等
我相信初学者肯定会对这些名词感到困惑，就如同第一天我在面试时提出的问题：
“我就只会数学建模和西瓜皮上的那些算法，好奇的问一下深度学习是啥？”
这个问题对现在的我来说也相当困惑，当然我相信写完这篇文章会让我的理顺这些东西

## preliminary knowledge

首先，给我整个 AI 的框架

```
人工智能（Artificial Intelligence, AI）
│
├── 机器学习（Machine Learning, ML）
│   ├── 监督学习（Supervised Learning）
│   ├── 无监督学习（Unsupervised Learning）
│   ├── 强化学习（Reinforcement Learning, RL）
│   └── 其他（半监督、主动学习等）
│
├── 深度学习（Deep Learning, DL）
│   ├── 神经网络（CNN, RNN, Transformer）
│   ├── 自监督学习（Self-supervised）
│   ├── 生成模型（GAN, Diffusion, VAE）
│   └── PINNs / SciML（物理引导模型）
│
└── 应用领域
    ├── NLP（自然语言处理）
    ├── CV（计算机视觉）
    ├── Speech（语音）
    └── 多模态 / 大模型（GPT, Gemini, etc.）

```

按照参差结构来讲，先从最简单的开始吧

### 1. 应用领域

搜索算法，符号推理这些其实都可以类比到实习中的“搜推广”（搜索推荐广告）算法工程师。这些东西其实都可以归结为应用领域或技术范式。如下所示
| 名称 | 类别 | 解释 |
| ------------------------- | ------- | ------------------------------------- |
| **NLP（自然语言处理）** | 应用领域 | 使用深度学习模型（如 Transformer）处理文本 |
| **CV（计算机视觉）** | 应用领域 | 使用 CNN 或 ViT 处理图像 |
| **Diffusion / GAN / VAE** | 生成模型 | 深度学习中的一种模型类型（生成任务） |
| **大模型（Foundation Model）** | 模型规模/范式 | 基于深度学习（Transformer）的通用大模型，如 GPT、Gemini |

### 2. 机器学习

机器学习就是大部分西瓜皮上的内容了，他的本意就是“让计算机自己去学习”，所以就会自然而言的牵扯到两大类别，即无监督学习和有监督学习，具体含义如下
| 类型 | 中文含义 | 训练方式 | 示例 |
|------|-----------|-----------|------|
| **监督学习 (Supervised Learning)** | 有标签学习 | 已知输入与期望输出，通过最小化预测误差进行训练 | 分类、回归、图像识别 |
| **无监督学习 (Unsupervised Learning)** | 无标签学习 | 在未标注数据中自动提取潜在结构或模式 | 聚类、降维、自编码器 |
| **强化学习 (Reinforcement Learning)** | 奖励驱动学习 | 智能体与环境交互，通过试错获得最大累计奖励 | 游戏 AI、机器人控制 |

对于强化学习而言，这部分会在后续着重介绍（因为我真的不懂）。但是一般而言，按照“想让机器学到什么”的定义，又可如下分类
· 监督学习用于“从已有示例中学习”
· 无监督学习用于“理解数据结构”
· 强化学习用于“学习行动策略”

### 3. 深度学习

深度学习是机器学习的一个重要分支，可以理解为使用多层神经网络（Neural Networks）自动学习数据特征的一类方法
换句话说，它依然遵循“最小化误差（loss function）”的思想，但与传统机器学习不同，  
深度学习不再需要人手去“提取特征”，而是通过层层网络结构自动完成特征提取与抽象表示

从集合关系上看：
深度学习 ⊂ 神经网络 ⊂ 机器学习 ⊂ 人工智能
例子：
| 层级 | 学到的特征（以图像识别为例） |
|------|--------------------|
| 第 1 层 | 学到边缘、线条等简单模式 |
| 第 2 层 | 学到角点、纹理、局部形状 |
| 第 3 层 | 学到眼睛、鼻子等复杂结构 |
| 第 4 层及以上 | 学到“猫脸”“汽车”等语义概念 |

## difference between Deep Learning（DL） and machine Learning（ML）

尽管两者的本质都是最小化误差（如 loss function），但核心目的是不同的。ML 的目的是寻找使预测误差最小的参数。（比如在 n 次线性函数中找最优参数，神经网络调整通过 Adam 反向传播调整网络权重）
| 算法 | 优化目标 | 损失函数举例 |
| ---- | ------- | ------------------ |
| 线性回归 | 拟合直线 | MSE（均方误差） |
| 逻辑回归 | 分类概率 | 交叉熵（Cross Entropy） |
| SVM | 最大化间隔 | Hinge Loss |
| 决策树 | 信息增益最大化 | 熵（Entropy） |

DL 也确实是继承了这个想法（最小化误差），但它的关键区别在于 “模型复杂度” 和 “特征获取方式”
| 方面 | 机器学习（ML） | 深度学习（DL） |
| ---- | --------------------------- | --------------- |
| 特征 | 需要人工提取（feature engineering） | 网络自动学习特征 |
| 模型结构 | 简单模型（线性/树/核函数） | 多层非线性神经网络 |
| 参数规模 | 少（几十～几百） | 多（百万～数十亿） |
| 优化方法 | 梯度下降、凸优化 | 反向传播 + SGD/Adam |
| 可解释性 | 强 | 弱 |
| 数据需求 | 较少 | 巨量数据 |

其实可以理解为，DL 本质就是神经网络，只是这个网络又大（神经元）又深（多层）。深度学习不只是有神经网络，还包括优化算法、损失函数、正则化、数据增强等。神经网络是模型，深度学习是方法。
最大的目的就是：**为了学习特征。区别在于可以更好的处理高度非线形问题**

## 强化学习

说了这么多，终于可以讲强化学习了，强化学习是让智能体（Agent）通过与环境（Environment）交互，并根据奖励（Reward）反馈，学习最优决策策略（Policy）的方法。
需要注意的是，这是一个最大化优化，不是 loss 这样的最小化优化（奖励必然是越多越好）

继续举例五大基本元素
| 元素 | 英文 | 含义 | 举例（机器人走迷宫） |
| --------------- | ----- | ------------- | ---------- |
| **Agent** | 智能体 | 负责做决策的学习者 | 机器人本身 |
| **Environment** | 环境 | Agent 所处的世界 | 迷宫 |
| **State** | 状态（s） | 当前环境的观测 | 机器人现在的位置 |
| **Action** | 动作（a） | Agent 可以执行的操作 | 向上/下/左/右移动 |
| **Reward** | 奖励（r） | 环境给的反馈信号 | 到终点+1，撞墙-1 |

p-code 如下：

```
for episode in range(N):
    state = env.reset()     # Agent观察环境（init啦其实就是）
    while not done:     # 开始训练
        action = agent.select_action(state)     # 选择一个动作
        next_state, reward, done = env.step(action)     # 环境给出新的状态和奖励；
        agent.learn(state, action, reward, next_state)  # Agent根据奖励更新策略
        state = next_state

```

所以，强化学习不是预测一个矢量或标量，他的目的应该是学习一种**策略**

ps：some cases
| 领域 | 应用场景 | 说明 |
| ----- | ------------------- | ------------ |
| 游戏 | AlphaGo、Atari、Dota2 | 通过自我博弈学习最优策略 |
| 机器人控制 | 行走、抓取、平衡 | 连续动作空间优化 |
| 自动驾驶 | 路径规划、决策控制 | 学习最优驾驶策略 |
| 智能电网 | 城市能源优化（CityLearn） | 控制能耗和储能系统 |
| 金融 | 投资组合优化 | 最大化长期收益 |
