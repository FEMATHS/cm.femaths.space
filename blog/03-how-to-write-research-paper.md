---
title: å¦‚ä½•å†™å‡ºä¸€ç¯‡ä¼˜ç§€çš„ç§‘æŠ€è®ºæ–‡
authors: [Tanger]
tags: [ä»å…¥é—¨åˆ°å…¥åœŸï¼Ÿä¸ï¼Œæ˜¯ç²¾é€šï¼ç§‘æŠ€è®ºæ–‡å®Œå…¨æŒ‡å—]
date: 2025-06-08
priority: 3
---

# å¦‚ä½•å†™å‡ºä¸€ç¯‡ä¼˜ç§€çš„ç§‘æŠ€è®ºæ–‡

ç›¸ä¿¡çœ‹åˆ°è¿™é‡Œçš„æœ‹å‹ï¼Œå·²ç»å¯¹ä¸€ç¯‡ç§‘ç ”è®ºæ–‡ï¼ˆResearch Articleï¼‰çš„åŸºæœ¬ç»“æ„ç›¸å½“ç†Ÿæ‚‰äº†ã€‚ç§‘ç ”å·¥ä½œè€…æœ€å¸¸æ’°å†™çš„æ–‡ç« ç±»å‹ä¹‹ä¸€å°±æ˜¯é‡‡ç”¨ **IMRaD æ¨¡å¼** çš„ç ”ç©¶è®ºæ–‡ï¼Œå³åŒ…æ‹¬ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š

- **I â€“ Introductionï¼ˆå¼•è¨€ï¼‰**
- **M â€“ Methodsï¼ˆæ–¹æ³•ï¼‰**
- **R â€“ Resultsï¼ˆç»“æœï¼‰**
- **A â€“ Abstractï¼ˆæ‘˜è¦ï¼‰**
- **D â€“ Discussionï¼ˆè®¨è®ºï¼‰**

æˆ‘å°†ç»“åˆè‡ªå·±çš„ç»å†ï¼Œåˆ†äº«è®ºæ–‡å†™ä½œçš„ä¸€èˆ¬æµç¨‹ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ**è®ºæ–‡çš„æ’°å†™é¡ºåºé€šå¸¸å¹¶ä¸ç­‰åŒäºå…¶æœ€ç»ˆçš„æ’ç‰ˆç»“æ„**ã€‚åœ¨ç§‘ç ”å®è·µä¸­ï¼Œå†™ä½œå¾€å¾€æ˜¯ä»å·²æœ‰çš„ç ”ç©¶ç»“æœå‡ºå‘ï¼Œé€æ­¥å‘å‰ã€å‘åå»¶å±•çš„ã€‚

é€šå¸¸ï¼Œåœ¨å®Œæˆä¸€æ®µæ—¶é—´çš„å®éªŒæˆ–å»ºæ¨¡å·¥ä½œåï¼Œæˆ‘ä»¬é¦–å…ˆè·å¾—çš„æ˜¯ä¸€ç»„æ•°æ®æˆ–ç ”ç©¶ç»“æœã€‚å› æ­¤ï¼Œå†™ä½œå¾€å¾€æ˜¯ä» **Resultsï¼ˆç»“æœï¼‰** å¼€å§‹ï¼Œæ ¹æ®ç»“æœå†å»æ¢³ç†å¹¶ä¹¦å†™ **Methodsï¼ˆæ–¹æ³•ï¼‰**ï¼Œè¯´æ˜è¿™äº›ç»“æœæ˜¯å¦‚ä½•å¾—åˆ°çš„ã€‚éšåæ’°å†™ **Discussionï¼ˆè®¨è®ºï¼‰**ï¼Œå¯¹ç»“æœè¿›è¡Œåˆ†æå’Œè§£é‡Šï¼Œè¿›ä¸€æ­¥æ˜ç¡®å…¶æ„ä¹‰ä¸ä¸è¶³ä¹‹å¤„ã€‚

åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å†å›åˆ°å‰é¢ï¼Œæ’°å†™ **Introductionï¼ˆå¼•è¨€ï¼‰**ï¼Œæ¢³ç†ç ”ç©¶èƒŒæ™¯ã€åŠ¨æœºã€å·²æœ‰å·¥ä½œä¸åˆ›æ–°ç‚¹ã€‚æœ€åæ’°å†™ **Abstractï¼ˆæ‘˜è¦ï¼‰**ï¼Œå¯¹å…¨æ–‡è¿›è¡Œç®€æ´æ€»ç»“ã€‚

<!-- truncate -->

å› æ­¤ï¼Œæˆ‘ä»¬æ¨èçš„å®é™…å†™ä½œé¡ºåºå¦‚ä¸‹ï¼š

| è®ºæ–‡ç»“æ„ï¼ˆå‘è¡¨é¡ºåºï¼‰ | å®é™…å†™ä½œå»ºè®®é¡ºåº |
| :------------------: | :--------------: |
|       Abstract       |     Results      |
|     Introduction     |     Methods      |
|       Methods        |    Discussion    |
|       Results        |   Introduction   |
|      Discussion      |     Abstract     |

é‡‡ç”¨è¿™ç§å†™ä½œé¡ºåºï¼Œæœ‰åŠ©äºå›´ç»•æ ¸å¿ƒç ”ç©¶ç»“æœè¿›è¡Œæ¸…æ™°ã€æœ‰é€»è¾‘çš„è®ºæ–‡æ„å»ºï¼ŒåŒæ—¶é¿å…â€œè¾¹å†™è¾¹æƒ³â€çš„ä½æ•ˆå†™ä½œçŠ¶æ€ã€‚

## Abstractï¼ˆæ‘˜è¦ï¼‰

æ‘˜è¦ä½œä¸ºè®ºæ–‡çš„å¼€å¤´éƒ¨åˆ†ï¼Œæ˜¯æ•´ç¯‡æ–‡ç« çš„æ ¸å¿ƒæ€æƒ³æµ“ç¼©è¡¨è¾¾ã€‚ä»è¯»è€…çš„è§’åº¦æ¥çœ‹ï¼Œæ‘˜è¦å¾€å¾€æ˜¯ä»–ä»¬æ¥è§¦è®ºæ–‡çš„ç¬¬ä¸€æ®µæ–‡å­—ï¼Œå› æ­¤å…¶å†™ä½œè´¨é‡ç›´æ¥å½±å“è¯»è€…æ˜¯å¦æœ‰å…´è¶£ç»§ç»­é˜…è¯»ä¸‹å»ã€‚

### âœï¸ å†™ä½œå»ºè®®

ä¸€ä¸ªä¼˜ç§€çš„æ‘˜è¦åº”å½“åšåˆ°**æ¸…æ™°ï¼ˆclarityï¼‰ã€ç®€æ´ï¼ˆbrevityï¼‰ã€æ˜äº†ï¼ˆlucidityï¼‰**ï¼Œä¸ºäº†è¾¾æˆä»¥ä¸Šä¸‰ä¸ªç›®çš„ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨ä¸‰æ®µå¼æ¥å®Œæˆæ‘˜è¦çš„ä¹¦å†™ï¼Œè¿™ä¸ªç»“æ„èƒ½å¤Ÿå‡†ç¡®ä¼ è¾¾ç ”ç©¶çš„å…³é”®ä¿¡æ¯ï¼Œé€šå¸¸å¯ä»¥éµå¾ªä»¥ä¸‹åŸºæœ¬ç»“æ„ï¼š

### âœ… æ¨èç»“æ„æ¨¡æ¿

- **ç¬¬ä¸€æ®µ**ï¼š**ç ”ç©¶èƒŒæ™¯ä¸ç°çŠ¶**ï¼ˆç°å­˜é—®é¢˜æˆ–ç ”ç©¶ç©ºç™½ï¼‰
- **ç¬¬äºŒæ®µ**ï¼š**ç ”ç©¶æ–¹æ³•æˆ–è§£å†³æ–¹æ¡ˆ**ï¼ˆæœ¬ç ”ç©¶é‡‡ç”¨äº†ä»€ä¹ˆæ–¹æ³•ã€æ¨¡å‹æˆ–æ€è·¯ï¼‰
- **ç¬¬ä¸‰æ®µ**ï¼š**ä¸»è¦ç»“æœä¸ç»“è®º**ï¼ˆæœ€ç»ˆå‘ç°äº†ä»€ä¹ˆï¼Œæœ‰å“ªäº›è´¡çŒ®æˆ–æ„ä¹‰ï¼‰

è¿™æ ·çš„å†™ä½œæ¡†æ¶ä¸ä»…èƒ½å¤Ÿå¸®åŠ©è¯»è€…è¿…é€ŸæŠŠæ¡è®ºæ–‡çš„ç ”ç©¶é‡ç‚¹ï¼Œä¹Ÿä¸ºåç»­çš„å¼•è¨€å’Œæ­£æ–‡åšå¥½é“ºå«ã€‚

#### **ç¬¬ä¸€æ®µ**ï¼š**ç ”ç©¶èƒŒæ™¯ä¸ç°çŠ¶**ï¼ˆç°å­˜é—®é¢˜æˆ–ç ”ç©¶ç©ºç™½ï¼‰

é¦–å…ˆæ˜¯æè¿°ç°çŠ¶ï¼Œåœ¨æè¿°ç°çŠ¶ä¸­ä¸€èˆ¬é‡‡å–å…ˆæ‰¬åæŠ‘ï¼Œå…ˆè‚¯å®š XXX æŠ€æœ¯å·²ç»å–å¾—äº†æ˜¾è‘—è¿›å±•ï¼Œå†æŒ‡å‡ºå…¶ä»å­˜åœ¨çš„ä¸è¶³ä¹‹å¤„ã€‚è¿™äº›ä¸è¶³åº”ä¸æˆ‘ä»¬åç»­ç ”ç©¶æ‰€è¦è§£å†³çš„é—®é¢˜å¯†åˆ‡ç›¸å…³ï¼Œæ‰èƒ½ç¡®ä¿ç¬¬ä¸€æ®µåœ¨é€»è¾‘ä¸Šçš„è¿è´¯ä¸å¿…è¦æ€§ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬è¿˜å¾—ç®€è¦ä»‹ç»æˆ‘ä»¬æå‡ºçš„æ¨¡å‹ï¼Œå®ƒè·Ÿå…¶ä»–æ¨¡å‹çš„ä¸åŒä¹‹å¤„ï¼š

ä¾‹å¦‚ï¼š

> Sensor-based human activity recognition is now well developed, but there are still many challenges, such as insufficient accuracy in the identification of similar activities. To overcome this issue, we collect data during similar human activities using three-axis acceleration and gyroscope sensors. We developed a model capable of classifying similar activities of human behavior, and the effectiveness and generalization capabilities of this model are evaluated. Based on the standardization and normalization of data, we consider the inherent similarities of human activity behaviors by introducing the multi-layer classifier model.

#### **ç¬¬äºŒæ®µ**ï¼š**ç ”ç©¶æ–¹æ³•æˆ–è§£å†³æ–¹æ¡ˆ**ï¼ˆæœ¬ç ”ç©¶é‡‡ç”¨äº†ä»€ä¹ˆæ–¹æ³•ã€æ¨¡å‹æˆ–æ€è·¯ï¼‰

ç´§æ¥ç€åº”é˜æ˜æœ¬æ–‡æ‰€é‡‡ç”¨çš„ç ”ç©¶æ–¹æ³•ã€‚è¯¥éƒ¨åˆ†æ²¡æœ‰ä¸¥æ ¼çš„ç»“æ„è¦æ±‚ï¼Œä½†åº”ä»¥**å‡†ç¡®ä¼ è¾¾æ–¹æ³•æœ¬è´¨**ä¸ºé¦–è¦ç›®æ ‡ï¼Œå…¶æ¬¡æ‰è€ƒè™‘è¯­è¨€çš„**ç®€æ´ä¸å‡ç»ƒ**ã€‚åœ¨ç¡®ä¿è¡¨è¾¾å‡†ç¡®çš„å‰æä¸‹ï¼ŒåŠ›æ±‚ç”¨æœ€ç›´æ¥çš„æ–¹å¼è®©è¯»è€…ç†è§£æ‰€æå‡ºæ–¹æ³•çš„æ ¸å¿ƒæ€æƒ³ä¸å®æ–½æ–¹å¼ã€‚

ä¾‹å¦‚ï¼š

> The first layer of the proposed model is a random forest model based on the XGBoost feature selection algorithm. In the second layer of this model, similar human activities are extracted by applying the kernel Fisher discriminant analysis (KFDA) with feature mapping. Then, the support vector machine (SVM) model is applied to classify similar human activities.

#### **ç¬¬ä¸‰æ®µ**ï¼š**ä¸»è¦ç»“æœä¸ç»“è®º**ï¼ˆæœ€ç»ˆå‘ç°äº†ä»€ä¹ˆï¼Œæœ‰å“ªäº›è´¡çŒ®æˆ–æ„ä¹‰ï¼‰

æœ€åï¼Œæˆ‘ä»¬éœ€è¦ä»‹ç»æ¨¡å‹çš„å®éªŒç»“æœï¼ŒåŒ…æ‹¬è¿è¡Œæ•ˆç‡ã€æ€§èƒ½è¡¨ç°å’Œè¯„ä¼°æŒ‡æ ‡ï¼Œå¹¶çªå‡ºæ¨¡å‹çš„ä¼˜åŠ¿ã€‚è‡³æ­¤ï¼Œæ•´ä¸ªæ‘˜è¦çš„å†…å®¹å°±åŸºæœ¬å®Œæˆäº†ã€‚

ä¾‹å¦‚ï¼š

> Our model is experimentally evaluated, and it is also applied to four benchmark datasets: UCI DSA, UCI HAR, WISDM, and IM-WSHA. The experimental results demonstrate that the proposed approach achieves recognition accuracies of 97.69%, 97.92%, 98.12%, and 90.6%, indicating excellent recognition performance. Additionally, we performed K-fold cross-validation on the random forest model and utilized ROC curves for the SVM classifier to assess the modelâ€™s generalization ability. The results indicate that our multi-layer classifier model exhibits robust generalization capabilities.

## Introductionï¼ˆä»‹ç»ï¼‰

**â€œIntroductionâ€** é¡¾åæ€ä¹‰ï¼Œæ˜¯æ•´ç¯‡è®ºæ–‡çš„å¼€ç«¯ï¼Œå®ƒä¸ä»…ä»‹ç»ç ”ç©¶èƒŒæ™¯ä¸æ ¸å¿ƒæ¨¡å‹ï¼Œæ›´æ˜¯ä½œè€…ç«™åœ¨ä¸“ä¸šè§†è§’ï¼Œä»¥é€šä¿—ä¸”ä¸¥è°¨çš„è¯­è¨€å¼•å¯¼è¯»è€…ç†è§£å…¨æ–‡æ ¸å¿ƒæ€æƒ³çš„å…³é”®éƒ¨åˆ†ã€‚å°½ç®¡å¼•è¨€éƒ¨åˆ†æ²¡æœ‰å›ºå®šæ ¼å¼ï¼Œä½†å†™ä½œæ—¶ä»åº”éµå¾ªä¸€å®šçš„é€»è¾‘å’Œç»“æ„ï¼Œå¹¶ç»“åˆä¸æ–­ç»ƒä¹ å’Œç§¯ç´¯æå‡å†™ä½œè´¨é‡ã€‚ä¸€ä¸ªå¥½çš„ Introduction èƒ½å¤Ÿå¸®åŠ©ä¸äº†è§£ä½ ç ”ç©¶é¢†åŸŸçš„è¯»è€…ï¼Œåœ¨çŸ­æ—¶é—´å†…æŠŠæ¡è®ºæ–‡çš„ä¸»é¢˜ã€ç ”ç©¶æ„ä¹‰ä»¥åŠä½ åœ¨å…¶ä¸­çš„è´¡çŒ®ã€‚å› æ­¤ï¼ŒIntroduction ä¸æ˜¯èƒŒæ™¯çš„å †ç Œï¼Œè€Œæ˜¯ä¸€ä¸ªæ•…äº‹çš„å¼€ç«¯ã€‚

### âœï¸ å†™ä½œå»ºè®®

1. **å¤šé˜…è¯»ä¼˜ç§€å¼•è¨€**  
   åˆå­¦è€…åº”å¤šé˜…è¯»åŒé¢†åŸŸå†…é«˜æ°´å¹³è®ºæ–‡çš„å¼•è¨€éƒ¨åˆ†ï¼Œç‰¹åˆ«æ˜¯é¡¶ä¼šã€é¡¶åˆŠæ–‡ç« ä¸­çš„è¡¨è¾¾æ–¹å¼ã€èƒŒæ™¯é“ºé™ˆã€ç ”ç©¶åŠ¨æœºã€è´¡çŒ®æ€»ç»“ç­‰å†…å®¹ã€‚

2. **å°è¯•å†™å‡ºâ€œè‡ªå·±é£æ ¼â€çš„å¼•è¨€**  
   åœ¨æ¨¡ä»¿ä¸­é€æ­¥æ¢ç´¢å‡ºå±äºè‡ªå·±çš„è¯­è¨€é£æ ¼å’Œé€»è¾‘ç»“æ„ï¼Œç›®æ ‡æ˜¯ï¼šå³ä½¿è¯»è€…å¯¹è¯¥ç ”ç©¶é¢†åŸŸå¹¶ä¸ç†Ÿæ‚‰ï¼Œä¹Ÿèƒ½é€šè¿‡é˜…è¯»ä½ çš„ Introduction å¿«é€ŸæŒæ¡è®ºæ–‡çš„ç ”ç©¶åŠ¨æœºã€èƒŒæ™¯é—®é¢˜ä¸ç ”ç©¶æ„ä¹‰ã€‚

3. **é€»è¾‘æ¸…æ™°ã€å¾ªåºæ¸è¿›**  
   å¥½çš„å¼•è¨€å¾€å¾€ä» **å®è§‚èƒŒæ™¯** è®²èµ·ï¼Œé€æ­¥èšç„¦è‡³å½“å‰ç ”ç©¶çš„å…·ä½“é—®é¢˜ï¼Œç„¶åé˜è¿°å·²æœ‰å·¥ä½œçš„ä¸è¶³ï¼Œæœ€åè¯´æ˜ä½ çš„å·¥ä½œè§£å†³äº†ä»€ä¹ˆé—®é¢˜ï¼Œæœ‰å“ªäº›è´¡çŒ®ã€‚

4. **å‚è€ƒæ–‡çŒ®çš„ä½¿ç”¨**
   - å°½é‡å¼•ç”¨ **è¿‘ä¸‰å¹´å†…çš„ç ”ç©¶æˆæœ**ï¼Œä»¥ç¡®ä¿ä½ çš„ç ”ç©¶ç«‹è¶³äºå½“å‰å­¦æœ¯å‰æ²¿ï¼›
   - åªæœ‰åœ¨å¼•ç”¨å¥ åŸºæ€§ç†è®ºæˆ–æ–¹æ³•æ—¶ï¼Œæ‰å»ºè®®ä½¿ç”¨ä¸‰å¹´ä»¥ä¸Šç”šè‡³æ›´ä¹…çš„ç»å…¸æ–‡çŒ®ï¼›
   - æ¯ä¸€æ¡å¼•ç”¨éƒ½åº”èµ·åˆ°æ”¯æ’‘ä½ è®ºè¿°çš„ä½œç”¨ï¼Œè€Œä¸æ˜¯å †ç Œæ•°é‡ã€‚

### âœ… æ¨èç»“æ„æ¨¡æ¿

- **ç¬¬ä¸€æ®µ**ï¼šå¼•å…¥ç ”ç©¶èƒŒæ™¯å’Œé¢†åŸŸå‘å±•ç°çŠ¶ï¼›
- **ç¬¬äºŒæ®µ**ï¼šæŒ‡å‡ºå½“å‰ç ”ç©¶çš„æŒ‘æˆ˜ã€ç©ºç™½æˆ–æœªè§£å†³é—®é¢˜ï¼›
- **ç¬¬ä¸‰æ®µ**ï¼šæ¦‚è¿°ä½ çš„æ–¹æ³•ã€æ€è·¯æˆ–åˆ›æ–°ç‚¹ï¼›
- **ç¬¬å››æ®µ**ï¼šç®€æ˜æ‰¼è¦åœ°æ€»ç»“æœ¬æ–‡çš„ä¸»è¦è´¡çŒ®ã€‚

#### **ç¬¬ä¸€æ®µ**ï¼šå¼•å…¥ç ”ç©¶èƒŒæ™¯å’Œé¢†åŸŸå‘å±•ç°çŠ¶ï¼›

ä¾‹å¦‚ï¼š

> Human activity recognition (HAR) involves identifying various human behaviors through a series of observations of individuals and their surrounding environment [1]. HAR has been generally applied in many fields, such as security and surveillance [2], sports and fitness [3], industry and manufacturing [4], autonomous driving [5], and the references therein...

#### **ç¬¬äºŒæ®µ**ï¼šæŒ‡å‡ºå½“å‰ç ”ç©¶çš„æŒ‘æˆ˜ã€ç©ºç™½æˆ–æœªè§£å†³é—®é¢˜ï¼›

ä¾‹å¦‚ï¼š

> However, a problem was identified where single-classification models can cause confusion when distinguishing similar activities, such as ascending stairs and descending stairs. In a study conducted by Jansi et al. [23], they utilized chaotic mapping to compress raw tri-axial accelerometer data and extracted 38 time-domain and frequency-domain features. These features included mean, standard deviation, root mean square, dominant frequency coefficient, spectral energy, and others. They achieved a recognition accuracy of 83.22% in human activity recognition...

#### **ç¬¬ä¸‰æ®µ**ï¼šæ¦‚è¿°ä½ çš„æ–¹æ³•ã€æ€è·¯æˆ–åˆ›æ–°ç‚¹ï¼›

ä¾‹å¦‚ï¼š

> In this paper, we propose the XR-KS (detailed description is given in Section 2) design aimed at addressing the issue of confusion between similar activities. To address the issue of similar activity feature similarity, we propose an SVM classification approach that utilizes KFDA. This approach effectively categorizes similar activities. Additionally, we conducted classification experiments on four common benchmark datasets and performed detailed analyses on these datasets. We compared our model to mainstream classification models. Experimental results demonstrate that our model exhibits excellent classification performance...

#### **ç¬¬å››æ®µ**ï¼šç®€æ˜æ‰¼è¦åœ°æ€»ç»“æœ¬æ–‡çš„ä¸»è¦è´¡çŒ®ã€‚

ä¾‹å¦‚ï¼š

> The remaining sections of this paper are organized as follows: Section 2 provides a brief introduction to the work carried out in this paper, along with details about the dataset used. Section 3 conducts a basic data analysis and employs appropriate data preprocessing techniques. This section introduces our proposed approach for human motion, which is based on a multi-layer classifier. Section 4 presents the experimental setup, provides results for our proposed method on multiple datasets, and offers an analysis and discussion of these results. Finally, in Section 5, we will summarize the insights gathered from these experiments and outline future directions.

## Methods ï¼ˆæ–¹æ³•ï¼‰

æ–¹æ³•éƒ¨åˆ†åŒæ ·éœ€è¦å¹¿æ³›å‚è€ƒåŒé¢†åŸŸçš„æ–‡çŒ®ï¼Œäº†è§£è¯¥é¢†åŸŸåœ¨æ–¹æ³•æè¿°æ–¹é¢çš„å†™ä½œè§„èŒƒä¸è¡¨è¾¾æ–¹å¼ã€‚é€šå¸¸å»ºè®®å…ˆé˜æ˜æ•´ä½“ç ”ç©¶æ¡†æ¶ä¸æ ¸å¿ƒæ€è·¯ï¼Œå†é€æ­¥å±•å¼€æ¯ä¸ªå…³é”®æ­¥éª¤çš„å…·ä½“å®ç°ç»†èŠ‚ï¼Œä»¥ä¿è¯ç»“æ„æ¸…æ™°ã€å†…å®¹å®Œæ•´ï¼Œå¹¶ç¬¦åˆé€šè¡Œçš„å­¦æœ¯è¡¨è¾¾ä¹ æƒ¯ã€‚

### âœï¸ å†™ä½œå»ºè®®

- **å›¾æ–‡ç»“åˆï¼Œæå‡å¯è¯»æ€§**  
  å»ºè®®é‡‡ç”¨**æµç¨‹å›¾æˆ–åŸç†ç¤ºæ„å›¾ç»“åˆæ–‡å­—æè¿°**çš„æ–¹å¼ï¼Œç›´è§‚å±•ç¤ºæ–¹æ³•æ­¥éª¤ä¸æ¨¡å‹ç»“æ„ã€‚è¿™ç§æ–¹å¼æœ‰åŠ©äºè¯»è€…å¿«é€Ÿç†è§£æ•´ä½“æµç¨‹ä¸æŠ€æœ¯è·¯å¾„ï¼Œå°¤å…¶æ˜¯åœ¨æ–¹æ³•è¾ƒå¤æ‚æ—¶æ›´æ˜¾é«˜æ•ˆã€‚ä¾‹å¦‚ï¼Œä»¥ä¸‹å‡ å¹…å›¾å¯ç”¨äºæ¦‚æ‹¬æ–¹æ³•æ¡†æ¶æˆ–å…³é”®æ¨¡å—ï¼š

  ![1.jpg](https://s2.loli.net/2025/06/23/A2mhJESQIN9zKgV.jpg)  
  ![2.jpg](https://s2.loli.net/2025/06/23/rXQxM4KBhjmGEi2.jpg)  
  ![3.jpg](https://s2.loli.net/2025/06/23/bd9flHcDg5EGpeC.png)  
  ![4.png](https://s2.loli.net/2025/06/23/MWGm1gHEr3eFvOP.png)

- **æ–‡å­—æè¿°åº”éµå¾ªå­¦æœ¯è¡¨è¾¾è§„èŒƒ**  
  æ’°å†™æ–¹æ³•éƒ¨åˆ†æ—¶ï¼Œåº”å‚ç…§é¢†åŸŸå†…é«˜æ°´å¹³è®ºæ–‡çš„è¯­è¨€é£æ ¼ï¼Œç‰¹åˆ«æ˜¯åœ¨æœ¯è¯­ä½¿ç”¨ã€å¥å¼ç»„ç»‡å’Œé€»è¾‘æ¨è¿›æ–¹é¢ã€‚åº”é‡ç‚¹çªå‡ºæ–¹æ³•çš„åˆ›æ–°ç‚¹åŠä¸å·²æœ‰ç ”ç©¶çš„å¯¹æ¯”ï¼Œé¿å…ç©ºæ³›å™è¿°æˆ–å †ç Œç»†èŠ‚ã€‚

- **ç»“æ„æ¸…æ™°ï¼Œæœ¯è¯­ç»Ÿä¸€**  
  å»ºè®®å°†æ–¹æ³•åˆ’åˆ†ä¸ºå¤šä¸ªå­æ¨¡å—ï¼ˆå¦‚â€œæ•´ä½“æ¡†æ¶â€ã€â€œæ•°æ®é¢„å¤„ç†â€ã€â€œæ¨¡å‹ç»“æ„â€ã€â€œè®­ç»ƒç­–ç•¥â€ã€â€œè¯„ä¼°æŒ‡æ ‡â€ç­‰ï¼‰ï¼Œä½¿å†…å®¹å±‚æ¬¡åˆ†æ˜ï¼Œä¾¿äºè¯»è€…é€æ­¥ç†è§£ã€‚ç¡®ä¿å…³é”®æœ¯è¯­å‰åä¸€è‡´ï¼Œé¿å…æ··ç”¨æˆ–æ­§ä¹‰ã€‚

---

### âœ… æ¨èç»“æ„æ¨¡æ¿

è™½ç„¶æ–¹æ³•éƒ¨åˆ†æ²¡æœ‰å”¯ä¸€æ ¼å¼ï¼Œä½†ä¸‹é¢è¿™ç§ç»“æ„é€»è¾‘æ¸…æ™°ã€è¯­è¨€å­¦æœ¯ï¼Œé€‚åˆä½œä¸ºå†™ä½œå‚è€ƒï¼š

#### 3.3. Second-Layer SVM Classification Based on Kernel Fisher Discriminant Analysis

In Figure 6, we observe challenges in classifying actions such as ascending and descending stairs due to intricate details. Additionally, Figure 7 reveals that PCA and small intra-class distances in the original features hinder effective classification. To mitigate confusion between similar actions, we employ two key steps. First, we employ KFDA (kernel Fisher discriminant analysis) for feature dimensionality reduction to improve the discrimination of similar activities. This aims to increase the separation between distinct actions in the data space, thereby facilitating subsequent SVM classification. The workflow mirrors the one shown in Figure 8.

![10.png](https://s2.loli.net/2025/06/24/1JmYhBDncX8aEqk.png)
Figure 6. Confusion matrix of test set and training set random forest training. (The experimental setup is like the one in Figure 9). (a) Confusion matrix of random forest model by train set; (b) confusion matrix of random forest model by test set. (a) (b)

![11.png](https://s2.loli.net/2025/06/24/mo8XdZK4haWsx2e.png)
Figure 7. Primary feature and PCA feature. (a) Origin data; (b) data after PCA. Figure 6. Confusion matrix of test set and training set random forest training. (The experimental setup is like the one in Figure 9). (a) Confusion matrix of random forest model by train set; (b) confusion matrix of random forest model by test set.

![4.png](https://s2.loli.net/2025/06/23/MWGm1gHEr3eFvOP.png)

Figure 8. SVM model workflow based on kernel Fisher discriminant analysis.(The second-layer classification model ensures close proximity for (a) similar activities. (b) After applying KFDA, (c) 3 axial data and images are generated. (d) The two-dimensional data for the 2 axial image, (e) SVM classification, (f) the final results).

![12.png](https://s2.loli.net/2025/06/24/6SIajBixboQ25WN.png)
Figure 9. Comparison chart of random forest model recognition results. (The training and test set ratio was set to 9:1, and the experiment was repeated five times.) (a) Radom forest model by train set; (b) random forest model by test set.

3.3.1. Principle of Kernel Fisher Discriminant Analysis KFDA is a pattern recognition and classification method based on kernel techniques and is an extension of Fisher discriminant analysis. KFDA is designed to handle nonline

...

![13.png](https://s2.loli.net/2025/06/24/xLwJt2p1hl58d6U.png)

### ğŸ“Œ æ€»ç»“

ä»ä¸Šä¾‹å¯ä»¥çœ‹å‡ºï¼Œé«˜è´¨é‡çš„æ–¹æ³•éƒ¨åˆ†é€šå¸¸åŒ…å«ä»¥ä¸‹å‡ ç±»å›¾è¡¨ï¼š

- **æµç¨‹å›¾**ï¼šå±•ç°æ•´ä½“æ–¹æ³•æµç¨‹æˆ–æ•°æ®æµåŠ¨ï¼ˆå¦‚ Figure 8ï¼‰
- **ç¤ºæ„å›¾**ï¼šè§£é‡Šæ¨¡å‹åŸç†æˆ–ç»“æ„ï¼ˆå¦‚ Figure 10ï¼‰
- **å®éªŒå›¾è¡¨**ï¼šå±•ç¤ºæ¨¡å‹è®­ç»ƒä¸æµ‹è¯•ç»“æœï¼ˆå¦‚ Figure 6, 9ï¼‰
- **æ•°æ®å¯¹æ¯”å›¾**ï¼šå±•ç¤ºåŸå§‹ä¸å¤„ç†åçš„æ•°æ®å·®å¼‚ï¼ˆå¦‚ Figure 7ï¼‰
- **ä¼ªä»£ç /æ¨¡å—åˆ†è§£å›¾**ï¼šç”¨äºå±•ç¤ºå…·ä½“ç®—æ³•ç»†èŠ‚ï¼ˆAlgorithm 2ï¼‰

å¦‚æœä½ å‘ç°ä½ çš„æ–¹æ³•æè¿°ä¸­ç¼ºä¹ä¸Šè¿°å›¾ç±»ï¼Œå»ºè®®è¡¥å……ç›¸åº”å†…å®¹ï¼Œä»¥å¢å¼ºè®ºæ–‡çš„å®Œæ•´æ€§ä¸è¯´æœåŠ›ã€‚

## Results ï¼ˆç»“æœï¼‰

åœ¨ç»“æœæˆ–è€…è¯´å®éªŒéƒ¨åˆ†ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯å‘ˆç°å®éªŒçš„ä¸»è¦å‘ç°ï¼Œå¹¶é€šè¿‡æ–‡å­—å¯¹ç»“æœä¸­å‡ºç°çš„ç°è±¡è¿›è¡Œè§£é‡Šä¸åˆ†æã€‚è¿™ä¸ä»…åŒ…æ‹¬æ•°æ®çš„å¯¹æ¯”ä¸è¶‹åŠ¿çš„æè¿°ï¼Œæ›´é‡è¦çš„æ˜¯å›ç­”ä»¥ä¸‹å‡ ä¸ªå…³é”®é—®é¢˜ï¼šç»“æœè¯´æ˜äº†ä»€ä¹ˆï¼Ÿæ˜¯å¦éªŒè¯äº†é¢„æœŸå‡è®¾ï¼Ÿåˆèƒ½å¾—å‡ºå“ªäº›å…·æœ‰å®é™…æ„ä¹‰çš„ç»“è®ºï¼Ÿ

ä¸ºäº†æ’°å†™å‡ºé«˜è´¨é‡çš„ç»“æœåˆ†ææ®µè½ï¼Œç§‘ç ”äººå‘˜é€šå¸¸ä¼šä½¿ç”¨ä¸€äº›åœ¨å­¦æœ¯å†™ä½œä¸­**çº¦å®šä¿—æˆ**çš„è¡¨è¾¾æ–¹å¼å’Œæœ¯è¯­ã€‚è¿™ç±»è¯­è¨€ä¸ä»…èƒ½å¢å¼ºè®ºè¿°çš„ä¸¥è°¨æ€§ï¼Œä¹Ÿæœ‰åŠ©äºåœ¨å›½é™…äº¤æµä¸­ä¿æŒæ¸…æ™°ä¸€è‡´çš„è¡¨è¾¾ã€‚æŒæ¡è¿™äº›â€œå­¦æœ¯è¡¨è¾¾å¥å¼â€çš„æœ€ä½³æ–¹å¼ä¹‹ä¸€ï¼Œå°±æ˜¯æ·±å…¥é˜…è¯»æœ¬é¢†åŸŸå·²å‘è¡¨çš„é«˜æ°´å¹³è®ºæ–‡ï¼Œæ¨¡ä»¿å…¶è¡¨è¿°ä¹ æƒ¯ä¸é€»è¾‘ç»“æ„ï¼Œå¹¶é€æ­¥å†…åŒ–ä¸ºè‡ªå·±çš„å†™ä½œèƒ½åŠ›ã€‚

### âœï¸ å†™ä½œå»ºè®®ï¼šå¦‚ä½•æ’°å†™å®éªŒç»“æœéƒ¨åˆ†

- **æ¸…æ™°å‘ˆç°ç»“æœï¼Œå›¾è¡¨ + æ–‡å­—ç»“åˆæ›´æœ‰æ•ˆ**  
  åœ¨ç»“æœéƒ¨åˆ†ï¼Œåº”ä»¥å›¾è¡¨ä¸ºä¸»ã€æ–‡å­—ä¸ºè¾…ï¼Œå°†æ ¸å¿ƒå®éªŒç»“æœç›´è§‚å±•ç¤ºå‡ºæ¥ã€‚å¸¸è§çš„å›¾è¡¨åŒ…æ‹¬æŠ˜çº¿å›¾ã€æŸ±çŠ¶å›¾ã€çƒ­åŠ›å›¾ã€æ··æ·†çŸ©é˜µã€è¯¯å·®æ›²é¢å›¾ç­‰ã€‚æ–‡å­—éƒ¨åˆ†éœ€è¦å¯¹å›¾è¡¨è¿›è¡Œè¯´æ˜ï¼ŒåŒ…æ‹¬å±•ç¤ºäº†å“ªäº›å˜é‡ã€åæ˜ äº†ä»€ä¹ˆè¶‹åŠ¿æˆ–åˆ†å¸ƒã€å›¾ä¸­å„å…ƒç´ æ‰€ä»£è¡¨çš„å«ä¹‰ç­‰ã€‚åº”é¿å…å›¾è¡¨ä¸æ­£æ–‡å†…å®¹å‰²è£‚ï¼Œç¡®ä¿å›¾æ–‡èƒ½å¤Ÿç›¸äº’è¡¥å……ã€å…±åŒè¯´æ˜é—®é¢˜ã€‚

- **è§£é‡Šç°è±¡ï¼Œé¿å…åªâ€œå¤è¿°å›¾è¡¨â€**  
  æ–‡å­—æè¿°ä¸èƒ½ä»…åœç•™åœ¨å¯¹å›¾è¡¨å†…å®¹çš„è½¬è¿°å±‚é¢ï¼Œè€Œåº”è¿›ä¸€æ­¥åˆ†æç»“æœèƒŒåçš„æˆå› å’Œé€»è¾‘ã€‚å³ï¼Œåœ¨æŒ‡å‡ºâ€œå‘ç”Ÿäº†ä»€ä¹ˆâ€çš„åŸºç¡€ä¸Šï¼Œè¿˜è¦å›ç­”â€œä¸ºä»€ä¹ˆä¼šè¿™æ ·â€ã€‚è¿™å¯èƒ½æ¶‰åŠæ¨¡å‹è®¾è®¡å¯¹æ€§èƒ½çš„å½±å“ã€è®­ç»ƒè¿‡ç¨‹ä¸­çš„å‚æ•°å˜åŒ–ã€æ•°æ®æœ¬èº«çš„æ€§è´¨ã€å®éªŒè®¾ç½®çš„åˆç†æ€§ç­‰æ–¹é¢ï¼Œä»è€Œä½“ç°å‡ºå¯¹å®éªŒç°è±¡çš„ç†è§£å’ŒæŒæ§ã€‚

- **ä¸é¢„æœŸç»“æœæˆ–åŸºçº¿æ–¹æ³•è¿›è¡Œå¯¹æ¯”**  
  ç»“æœåˆ†æä¸åº”å­¤ç«‹è¿›è¡Œï¼Œè€Œåº”å°†å½“å‰æ–¹æ³•ä¸å·²æœ‰æ–¹æ³•æˆ–é¢„æœŸæ•ˆæœè¿›è¡Œæ¯”è¾ƒï¼Œçªå‡ºæ”¹è¿›ç‚¹ä¸ä¼˜åŠ¿æ‰€åœ¨ã€‚å¯¹æ¯”å¯ä»¥æ˜¯å®šé‡çš„ï¼ˆå¦‚æŒ‡æ ‡å€¼å·®å¼‚ï¼‰ï¼Œä¹Ÿå¯ä»¥æ˜¯å®šæ€§çš„ï¼ˆå¦‚é²æ£’æ€§ã€å¯è§£é‡Šæ€§ã€æ³›åŒ–èƒ½åŠ›çš„æå‡ç­‰ï¼‰ã€‚æ­¤å¤–ï¼Œè¿˜åº”æ³¨æ„è¯´æ˜æ¯”è¾ƒçš„å…¬å¹³æ€§ï¼Œå¦‚æ˜¯å¦ä½¿ç”¨äº†ç›¸åŒçš„æ•°æ®é›†ã€å‚æ•°è®¾ç½®æ˜¯å¦ä¸€è‡´ç­‰ï¼Œä»¥ä¿è¯ç»“è®ºçš„å¯ä¿¡åº¦ã€‚

- **é¿å…ä¸»è§‚æè¿°ï¼Œå°½é‡é‡åŒ–ç»“è®º**  
  å®éªŒç»“è®ºåº”å»ºç«‹åœ¨å®¢è§‚æ•°æ®çš„åŸºç¡€ä¸Šï¼Œé¿å…ä½¿ç”¨æ¨¡ç³Šæˆ–æƒ…ç»ªåŒ–çš„è¯­è¨€ï¼Œå¦‚â€œæ•ˆæœå¾ˆå¥½â€ã€â€œæ˜¾è‘—æé«˜â€ç­‰ã€‚åº”ä¼˜å…ˆä½¿ç”¨å…·ä½“æŒ‡æ ‡ï¼ˆå¦‚å‡†ç¡®ç‡ã€å¬å›ç‡ã€F1 åˆ†æ•°ã€RMSEã€MAE ç­‰ï¼‰è¿›è¡Œè¯´æ˜ï¼Œå¹¶ç»“åˆæ•°å€¼å˜åŒ–ã€æå‡å¹…åº¦ã€ç»Ÿè®¡æ˜¾è‘—æ€§ç­‰æ–¹é¢å±•å¼€åˆ†æã€‚è¿™æ ·å¯ä»¥ä½¿ç»“æœæ›´å…·è¯´æœåŠ›å’Œå¯é‡å¤æ€§ã€‚

- **æ€»ç»“å…³é”®å‘ç°ï¼Œè¡”æ¥è®¨è®ºæˆ–ç»“è®ºéƒ¨åˆ†**  
  åœ¨ç»“æœéƒ¨åˆ†ç»“å°¾ï¼Œå»ºè®®å¯¹å½“å‰å®éªŒç»“æœè¿›è¡Œç®€è¦æ€»ç»“ï¼Œæç‚¼å‡ºå…³é”®å‘ç°ï¼Œå¹¶ä¸ºåç»­çš„è®¨è®ºæˆ–ç»“è®ºéƒ¨åˆ†åšå¥½é“ºå«ã€‚è¿™å¯ä»¥åŒ…æ‹¬ç¡®è®¤æŸé¡¹å‡è®¾æ˜¯å¦æˆç«‹ã€æŸç§æ–¹æ³•æ˜¯å¦æœ‰æ•ˆã€æŸç±»ç‰¹å¾æ˜¯å¦èµ·åˆ°äº†å…³é”®ä½œç”¨ç­‰ï¼Œä¸ºæ•´ç¯‡è®ºæ–‡çš„é€»è¾‘é—­ç¯æ‰“ä¸‹åŸºç¡€ã€‚

### âœ… æ¨èç»“æ„æ¨¡æ¿

ç»“æœçš„ç¬¬ä¸€éƒ¨åˆ†åº”è¯¥ç®€å•ä»‹ç»ä¸€ä¸‹ç”µè„‘æ‰€ä½¿ç”¨çš„ç¡¬ä»¶é…ç½®ä»¥åŠç¯å¢ƒï¼Ÿä½¿ç”¨äº†ä»€ä¹ˆè½¯ä»¶ï¼Ÿï¼Œä»¥ç¡®ä¿å®éªŒå…·å¤‡å¯é‡å¤æ€§å’Œå¯¹æ¯”æ€§ã€‚ä»¥ä¸‹æ˜¯å¸¸ç”¨çš„å†™ä½œæ–¹å¼ï¼š

#### 4.1. Experimental Setting

The experiments were conducted in Guilin, China, on an ASUS computer with the following specifications: an AMD Ryzen 7 4800H processor with Radeon graphics, operating at 2.90 GHz, 16 GB of RAM, and an NVIDIA GeForce GTX 1660 Ti graphics card. The operating system used was Windows 10. We used both **MATLAB 2022R** and **Python 3.9.7** tools to conduct the experiments and validate them on four different datasets: **UCI DSA**, **UCI HAR**, **WISDM**, and **UCI ADL**. We also conducted a comprehensive evaluation of our approach. To maintain the conciseness of the paper, the following experiments are illustrated using the UCI DSA dataset as an example

ä¸æ–¹æ³•éƒ¨åˆ†ç±»ä¼¼ï¼Œ**ç»“æœéƒ¨åˆ†åŒæ ·å»ºè®®å›¾æ–‡ç»“åˆ**ï¼Œé€šè¿‡å›¾è¡¨å‘ˆç°å®éªŒæ•°æ®ï¼Œå¹¶é…ä»¥æ°å½“çš„æ–‡å­—è¯´æ˜ï¼Œä»¥å¢å¼ºè®ºæ–‡çš„å¯è¯»æ€§ä¸è¯´æœåŠ›ã€‚åˆç†çš„å›¾æ–‡æ­é…ä¸ä»…æœ‰åŠ©äºç›´è§‚å±•ç¤ºæ¨¡å‹æ€§èƒ½ã€å¯¹æ¯”å®éªŒæ•ˆæœï¼Œè¿˜èƒ½æ›´åŠ å……åˆ†åœ°å‘ˆç°å®éªŒè®¾è®¡çš„ä¸¥è°¨æ€§ä¸ç»“è®ºçš„å¯ä¿¡åº¦ï¼Œæ˜¯é«˜è´¨é‡è®ºæ–‡çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚

#### 4.2. Extraction of Important Features

By utilizing the XGBoost feature value selection algorithm to analyze the 45 features in the dataset, we can evaluate the relative importance of each feature. As shown in Figure 14b, we obtained different experimental results by using the first n features as input to the first layer of the random forest model. These results effectively demonstrate the accuracy and time consumption in various scenarios. Therefore, we selected the first 31 features from Figure 14a to be used in the subsequent multi-layer classifier based on generalized discriminant analysis. To mitigate potential interference with our classification accuracy, we filter out features with lower importance.

![14.png](https://s2.loli.net/2025/06/24/i8QjfykVOHDc6BN.png)

Figure 14. Weights of important features chart and effect of different numbers of features on a random model. (We set the number of features to be from 1 to 46 steps, took 5, and repeated the error experiment for each different n to obtain the mean and confidence interval.) (a) Result of the XGBoost feature value selection algorithm; (b) effect of different numbers of features on a random model.

Table 3. Number of features and error rate, accuracy rate, training times, and running time (mean Â± std).

![15.png](https://s2.loli.net/2025/06/24/sCwoquBryvG1lci.png)

## Discussion ï¼ˆè®¨è®ºï¼‰

### âœ… å†™ä½œå»ºè®®ï¼šConclusion æˆ– Discussion éƒ¨åˆ†

åœ¨ç§‘æŠ€è®ºæ–‡ä¸­ï¼Œ**è®¨è®ºï¼ˆDiscussionï¼‰æˆ–ç»“è®ºï¼ˆConclusionï¼‰éƒ¨åˆ†**ä¸»è¦ç”¨äºå¯¹å…¨æ–‡å†…å®¹è¿›è¡Œç®€è¦æ€»ç»“ï¼Œå¹¶æŒ‡å‡ºå½“å‰ç ”ç©¶çš„å±€é™æ€§ä¸æœªæ¥çš„æ”¹è¿›æ–¹å‘ã€‚

ç›¸æ¯”å‰æ–‡çš„æ–¹æ³•ã€å®éªŒä¸ç»“æœéƒ¨åˆ†ï¼Œè¿™ä¸€éƒ¨åˆ†çš„æ’°å†™ç›¸å¯¹ç®€æ´ï¼Œé‡ç‚¹ä¸åœ¨äºå†æ¬¡é‡å¤æŠ€æœ¯ç»†èŠ‚ï¼Œè€Œåœ¨äºï¼š

- **æç‚¼æ ¸å¿ƒå‘ç°**ï¼šç®€æ´å›é¡¾ç ”ç©¶æ‰€å–å¾—çš„ä¸»è¦æˆæœå’Œè´¡çŒ®ï¼›
- **åæ€ç ”ç©¶ä¸è¶³**ï¼šæŒ‡å‡ºå½“å‰å·¥ä½œä¸­çš„å±€é™æ€§ï¼Œå¦‚å®éªŒè®¾è®¡çš„é™åˆ¶ã€æ¨¡å‹é€‚ç”¨æ€§çš„èŒƒå›´ç­‰ï¼›
- **è¿›è¡Œå‰ç»æ€§å±•æœ›**ï¼šå¯ä»¥ç®€è¦æå‡ºæœªæ¥å¯èƒ½çš„ç ”ç©¶æ–¹å‘ã€æ–¹æ³•æ”¹è¿›æˆ–åº”ç”¨æ‹“å±•ã€‚

é€‚å½“æŒ‡å‡ºç ”ç©¶ä¸­å­˜åœ¨çš„é—®é¢˜æˆ–é™åˆ¶ï¼Œèƒ½å¤Ÿä½“ç°ä½œè€…çš„**å®¢è§‚æ€åº¦ä¸ç§‘å­¦ç²¾ç¥**ï¼Œä¹Ÿæ˜¯é«˜è´¨é‡è®ºæ–‡çš„é‡è¦æ ‡å¿—ä¹‹ä¸€ã€‚

### âœ… æ¨èç»“æ„æ¨¡æ¿

#### 5. Conclusion

In this paper, we proposed [ç®€è¦è¯´æ˜ä½ çš„æ–¹æ³•/æ¨¡å‹ï¼Œä¾‹å¦‚ï¼ša multi-layer classifier model based on XGBoost and GDA] to address the problem of [ç ”ç©¶ç›®æ ‡æˆ–æŒ‘æˆ˜ï¼Œä¾‹å¦‚ï¼šrecognizing similar human activities in sensor datasets]. Our approach was validated on multiple benchmark datasets, and the results demonstrate its effectiveness in terms of accuracy, robustness, and computational efficiency.

Despite these promising results, several limitations remain. First, [æŒ‡å‡ºä¸è¶³ï¼Œä¾‹å¦‚ï¼šthe model performance may degrade in the presence of noisy or missing sensor data]. Second, [ä¾‹å¦‚ï¼šthe generalizability of the model across different domains has not been extensively tested].

In future work, we plan to [å±•æœ›ï¼Œä¾‹å¦‚ï¼šexplore domain adaptation techniques to improve cross-dataset performance, and investigate the integration of temporal sequence modeling]. These improvements are expected to further enhance the practical applicability of our approach in real-world scenarios.

---

## æ€»ç»“

æœ¬æ–‡å›´ç»• IMRaD ç»“æ„ï¼Œç³»ç»Ÿä»‹ç»äº†ç§‘ç ”è®ºæ–‡çš„å†™ä½œæµç¨‹å’Œè¦ç‚¹ã€‚æ¨èå…ˆå†™ç»“æœï¼Œå†è¡¥å……æ–¹æ³•ã€è®¨è®ºï¼Œæœ€åå®Œæˆå¼•è¨€å’Œæ‘˜è¦ï¼Œä»¥ä¿è¯é€»è¾‘æ¸…æ™°ã€èšç„¦çªå‡ºã€‚

ğŸ“Œ **æ¬¢è¿å…³æ³¨ FEMATHS å°ç»„ä¸å±±æµ·æ•°æ¨¡ï¼ŒæŒç»­å­¦ä¹ æ›´å¤šæ•°å­¦å»ºæ¨¡ä¸ç§‘ç ”ç›¸å…³çŸ¥è¯†ï¼**

<p align="center">
  <img src="https://s2.loli.net/2025/06/12/9aDkEfKWvUMrjnm.jpg" alt="logo" />
</p>
